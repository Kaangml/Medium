{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":149630,"sourceType":"modelInstanceVersion","modelInstanceId":127020,"modelId":149965}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.applications import ResNet50\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io\nimport cv2 \nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\nimport seaborn as sns\nfrom tqdm import tqdm\nimport gc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Veri yolu\ntrain_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/'\nval_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/'\ntest_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test'\n# Sınıf isimleri\nclass_names = ['NORMAL', 'PNEUMONIA']\n\n# Sınıf dağılımını sayma\ntrain_counts = {class_name: len(os.listdir(os.path.join(train_dir, class_name))) for class_name in class_names}\nval_counts = {class_name: len(os.listdir(os.path.join(val_dir, class_name))) for class_name in class_names}\ntest_counts = {class_name: len(os.listdir(os.path.join(test_dir, class_name)))for class_name in class_names}\n# Sonuçları yazdırma\nprint(\"Eğitim seti sınıf dağılımı:\", train_counts)\nprint(\"Doğrulama seti sınıf dağılımı:\", val_counts)\nprint(\"Test seti sınıf dağılımı:\", test_counts)\n\n# Görselleştirme\nplt.bar(train_counts.keys(), train_counts.values(), color=['blue', 'orange'])\nplt.title('Eğitim Seti Sınıf Dağılımı')\nplt.ylabel('Örnek Sayısı')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\n\n# Görüntüleri yüklemek için fonksiyon\ndef load_random_images_from_class(directory, class_name, num_images=2, target_size=(224, 224)):\n    class_dir = os.path.join(directory, class_name)\n    image_files = random.sample(os.listdir(class_dir), num_images)  # Rastgele görüntüler seç\n    \n    images = []\n    for img_file in image_files:\n        img_path = os.path.join(class_dir, img_file)\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (target_size[1], target_size[0]))  # Boyutlandır\n        \n        # Eğer gri tonlamalı (tek kanallı) bir görüntü ise, RGB formatına çevir\n        if img.ndim == 2:\n            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n        images.append(img)\n    return images\n\n# Normal sınıfından iki görüntü, Pneumonia sınıfından iki görüntü seçelim\nnormal_images = load_random_images_from_class(train_dir, 'NORMAL', num_images=2)\npneumonia_images = load_random_images_from_class(train_dir, 'PNEUMONIA', num_images=2)\n\n# Seçilen görüntüleri yan yana gösterme\nfig, axes = plt.subplots(1, 4, figsize=(15, 5))\n\nfor i, img in enumerate(normal_images + pneumonia_images):\n    axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    axes[i].axis('off')\n    if i < 2:\n        axes[i].set_title('NORMAL')\n    else:\n        axes[i].set_title('PNEUMONIA')\nplt.savefig('ornek2.png')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Sınıf isimleri\nclass_names = ['NORMAL', 'PNEUMONIA']\n\n# Veri yükleme fonksiyonu\ndef load_data_from_directory(directory, target_size=(224, 224)):\n    images = []\n    labels = []\n\n    for label, class_name in enumerate(class_names):\n        class_dir = os.path.join(directory, class_name)\n        \n        # Dosyaları döngüye almak için tqdm kullanma\n        for filename in tqdm(os.listdir(class_dir), desc=f'Loading {class_name}', unit='file'):\n            if filename.lower().endswith(('.jpeg', '.jpg', '.png')):  # Sadece resim dosyalarını al\n                img_path = os.path.join(class_dir, filename)\n                img = io.imread(img_path)  # Görüntüyü oku\n                \n                # Görüntü boyutunu kontrol et\n                if img.shape[0] < target_size[0] or img.shape[1] < target_size[1]:\n                    #print(f\"Boyut küçük, atlanıyor: {img.shape} - Dosya: {img_path}\")\n                    continue  # Boyut küçükse geç\n                \n                # Görüntüyü yeniden boyutlandırma\n                img = cv2.resize(img, (target_size[1], target_size[0]))  # OpenCV'de (y, x) şeklinde belirtilir\n\n                # Eğer görüntü tek kanallı ise, 3 kanallı hale getir\n                if img.ndim == 2:  # Gri tonlamalı (1 kanal)\n                    img = np.stack((img,)*3, axis=-1)\n                \n                # RGB görüntü kontrolü\n                if img.shape == (target_size[0], target_size[1], 3):  # RGB görüntü\n                    images.append(img)\n                    labels.append(label)\n                else:\n                    print(f\"Uygun olmayan boyut: {img.shape} - Dosya: {img_path}\")\n\n    return np.array(images), np.array(labels)\n\n# Eğitim, doğrulama ve test verilerini yükleme\ntrain_images, train_labels = load_data_from_directory(train_dir)\nval_images, val_labels = load_data_from_directory(val_dir)\ntest_images, test_labels = load_data_from_directory(test_dir)\n\n# Boyutları kontrol et\nprint(\"Train images shape:\", train_images.shape)\nprint(\"Train labels shape:\", train_labels.shape)\nprint(\"Val images shape:\", val_images.shape)\nprint(\"Val labels shape:\", val_labels.shape)\nprint(\"Test images shape:\", test_images.shape)\nprint(\"Test labels shape:\", test_labels.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Data augmentation tanımlama\ndata_gen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Sınıf dağılımı fonksiyonu\ndef get_class_distribution(images, labels):\n    return {\n        0: len(images[labels == 0]),  # NORMAL\n        1: len(images[labels == 1])   # PNEUMONIA\n    }\n\n# Verileri birleştirirken sadece gerekli miktarda sınıf verilerini al\ndef balanced_data_merge(train_images, val_images, test_images, train_labels, val_labels, test_labels):\n    # Tüm verileri birleştirme\n    all_images = np.concatenate((train_images, val_images, test_images), axis=0)\n    all_labels = np.concatenate((train_labels, val_labels, test_labels), axis=0)\n\n    # Bellek temizliği\n    del train_images, val_images, test_images\n    del train_labels, val_labels, test_labels\n    gc.collect()\n\n    # Sınıf dağılımını kontrol etme\n    class_distribution = get_class_distribution(all_images, all_labels)\n    avg_class_size = (class_distribution[0] + class_distribution[1]) / 2  # Ortalama sınıf sayısı\n\n    # PNEUMONIA sınıfında fazla veri varsa, fazla veriyi çıkaralım\n    if class_distribution[1] > avg_class_size:\n        pneumonia_images = all_images[all_labels == 1]  # PNEUMONIA görüntüleri\n        pneumonia_labels = all_labels[all_labels == 1]\n\n        # Fazla veriyi rastgele çıkarma\n        num_to_remove = class_distribution[1] - avg_class_size\n        indices_to_remove = np.random.choice(len(pneumonia_images), int(num_to_remove), replace=False)\n        pneumonia_images = np.delete(pneumonia_images, indices_to_remove, axis=0)\n        pneumonia_labels = np.delete(pneumonia_labels, indices_to_remove, axis=0)\n\n        # Güncellenmiş PNEUMONIA ve NORMAL verilerini birleştirme\n        normal_images = all_images[all_labels == 0]  # NORMAL görüntüleri\n        all_images = np.concatenate((normal_images, pneumonia_images), axis=0)\n        all_labels = np.concatenate((np.zeros(len(normal_images)), pneumonia_labels), axis=0)\n\n    return all_images, all_labels\n\n# Verileri birleştirme ve dengeleme\nall_images, all_labels = balanced_data_merge(train_images, val_images, test_images, train_labels, val_labels, test_labels)\ndel train_images, val_images, test_images\ndel train_labels, val_labels, test_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NORMAL sınıfındaki eksik verileri artırma\nclass_distribution = get_class_distribution(all_images, all_labels)\nnum_to_augment = int((class_distribution[1] + class_distribution[0]) / 2 - class_distribution[0])\n\nif num_to_augment > 0:\n    normal_images = all_images[all_labels == 0]  # NORMAL görüntüleri\n\n    # Data augmentation uygulama\n    augmented_images = []\n    for img in normal_images:\n        img = img.reshape((1,) + img.shape)  # (1, yükseklik, genişlik, kanallar)\n        for batch in data_gen.flow(img, batch_size=1):\n            augmented_images.append(batch[0].astype(np.uint8))\n            if len(augmented_images) >= num_to_augment:\n                break\n\n    # Artırılmış verileri ekleme\n    augmented_images = np.array(augmented_images)\n    all_images = np.concatenate((all_images, augmented_images), axis=0)\n    all_labels = np.concatenate((all_labels, np.zeros(len(augmented_images))), axis=0)\n\n# Verileri X, y şeklinde ayırma\nX = all_images\ny = all_labels\n\n# Bellek temizliği\ndel all_images\ndel all_labels\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X ve y'yi dosyaya kaydetme\nnp.save('X_data.npy', X)  # X verilerini kaydet\nnp.save('y_data.npy', y)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X\ndel y\n# Verileri yükleme\nX_loaded = np.load('/kaggle/working/X_data.npy')  # X verilerini yükle\ny_loaded = np.load('/kaggle/working/y_data.npy')  # y etiketlerini yükle\n\nprint(\"Yüklenen X şekli:\", X_loaded.shape)\nprint(\"Yüklenen y şekli:\", y_loaded.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.astype(int)\n# Eğitim ve test setlerine ayırma\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\nprint(\"Eğitim seti boyutu:\", X_train.shape, y_train.shape)\nprint(\"Test seti boyutu:\", X_test.shape, y_test.shape)\n\n# Verilerin dengesizliğini kontrol etme\nunique, counts = np.unique(y_train, return_counts=True)\nprint(\"Eğitim seti sınıf dağılımı:\", dict(zip(unique, counts)))\n\ndel X\ndel y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Manuel olarak indirilen dosya yolu\nlocal_weights_path = '/kaggle/input/resnet50_weights_tf_dim_ordering_tf_kernels_notop/tensorflow2/default/1/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# ResNet50 modelini indirilen ağırlıklarla yükleme\nbase_model = ResNet50(weights=local_weights_path, include_top=False, input_shape=(224, 224, 3))\n\n# Katmanları dondurma\nfor layer in base_model.layers[:-4]:  # Son 4 katmanı dondurmadan bırakıyoruz\n    layer.trainable = False\n\n# Modelin son katmanlarını değiştirelim\nmodel = Sequential([\n    base_model,\n    Flatten(),\n    Dense(256, activation='relu'),  \n    Dropout(0.5), \n    Dense(1, activation='sigmoid')  # İkili sınıflandırma için sigmoid aktivasyonu kullanıyoruz\n])\n\n# Modelin eğitim parametrelerini ayarlama\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Callbacks tanımlama\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\nmodel_checkpoint = ModelCheckpoint('/best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n\n# Modelin eğitilmesi\nhistory = model.fit(\n    X_train,  # Eğitim verileri\n    y_train,  # Eğitim etiketleri\n    epochs=10,     # Eğitim dönemi sayısı\n    validation_split=0.2,  # Doğrulama verileri\n    batch_size=32,  # Batch boyutu\n    callbacks=[reduce_lr, early_stopping, model_checkpoint]  # Callbacks ekleme\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n\n# Modeli kaydetme\nmodel.save('my_model.keras')  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eğitim geçmişinin görselleştirilmesi\nplt.figure(figsize=(12, 4))\n\n# Loss grafiği\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Eğitim Kaybı')\nplt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\nplt.title('Model Kaybı')\nplt.xlabel('Epoch')\nplt.ylabel('Kaybı')\nplt.legend()\n\n# Doğruluk grafiği\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\nplt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\nplt.title('Model Doğruluğu')\nplt.xlabel('Epoch')\nplt.ylabel('Doğruluk')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC Eğrisi ve AUC Hesaplama\ny_pred_proba = model.predict(X_test).ravel()  # Test verileri üzerindeki tahminler\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\n# ROC Eğrisinin Görselleştirilmesi\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC Eğrisi (AUC = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Karışıklık Matrisi Hesaplama\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Tahminler\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Karışıklık Matrisinin Görselleştirilmesi\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['NORMAL', 'PNEUMONIA'], \n            yticklabels=['NORMAL', 'PNEUMONIA'])\nplt.ylabel('Gerçek Etiketler')\nplt.xlabel('Tahmin Edilen Etiketler')\nplt.title('Karışıklık Matrisi')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sınıflandırma Raporu\nreport = classification_report(y_test, y_pred, target_names=['NORMAL', 'PNEUMONIA'])\nprint(\"Sınıflandırma Raporu:\\n\", report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}